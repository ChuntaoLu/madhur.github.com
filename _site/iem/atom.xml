<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Inductio Ex Machina</title>
 <link href="http://mark.reid.name/iem/atom.xml" rel="self"/>
 <link href="http://mark.reid.name/iem/"/>
 <updated>2011-01-01T00:41:07+07:00</updated>
 <id>http://mark.reid.name/iem/</id>
 <author>
   <name>Mark Reid</name>
   <email>mark@reid.name</email>
 </author>
 
 
 <entry>
   <title>MetaOptimize Q+A</title>
   <link href="http://mark.reid.name/iem/metaoptimize.html"/>
   <updated>2010-07-03T00:00:00+07:00</updated>
   <id>id:/iem/metaoptimize</id>
   <content type="html">&lt;p&gt;This is just a quick post to point any readers who have not heard of it already to the newly deployed &lt;a href='http://metaoptimize.com/qa/'&gt;MetaOptimize Q+A&lt;/a&gt;&amp;#8212;a question and answer site for machine learning, NLP, data mining, AI and related topics that describes itself as:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A community of data geeks interested in machine learning, natural language processing, artificial intelligence, text analysis, information retrieval, search, data mining, statistical modeling, and data visualization, as well as adjacent topics.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I&amp;#8217;ve had good experiences with related sites such as &lt;a href='http://stackoverflow.com'&gt;StackOverflow&lt;/a&gt; and particularly &lt;a href='http://mathoverflow.com'&gt;MathOverflow&lt;/a&gt;. So far I&amp;#8217;ve only had a chance to sign up and quickly look around MetaOptimize but from what I&amp;#8217;ve seen the users seem sharp, the questions on-topic, and the answers informative.&lt;/p&gt;

&lt;p&gt;This is a great addition to the burgeoning online machine learning community and &lt;a href='http://www-etud.iro.umontreal.ca/~turian/'&gt;Joseph Turian&lt;/a&gt; (&lt;a href='http://twitter.com/turian'&gt;@turian&lt;/a&gt;) has done a great job at setting the tone of the site as well as encouraging a number of solid researchers and practitioners to join before publicising it too widely.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;m really looking forward to participating more once I&amp;#8217;m back from holidays.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>ICML 2010 Discussion Site</title>
   <link href="http://mark.reid.name/iem/icml-discussion-site.html"/>
   <updated>2010-06-22T00:00:00+07:00</updated>
   <id>id:/iem/icml-discussion-site</id>
   <content type="html">&lt;p&gt;&lt;a href='http://www.icml2010.org'&gt;ICML 2010&lt;/a&gt; is already underway so I thought I would quickly mention the new &lt;a href='http://mldiscuss.appspot.com/'&gt;discussion site&lt;/a&gt; I built for it. I&amp;#8217;d like for the new version to improve on the earlier ones in terms of participation so, if you haven&amp;#8217;t done so already, head over to &lt;a href='http://mldiscuss.appspot.com/'&gt;ML Discuss&lt;/a&gt; and start discussing!&lt;/p&gt;

&lt;p&gt;This is the third year I have set up such a discussion site for ICML. The &lt;a href='http://conflate.net/icml/'&gt;previous two years&lt;/a&gt; were built upon a &lt;a href='http://dokuwiki.org/'&gt;wiki engine&lt;/a&gt; with a &lt;a href='http://www.dokuwiki.org/plugin:discussion'&gt;plugin&lt;/a&gt; that allows comments to be left on wiki pages. This worked fairly well but had one major drawback: it was not easy to be notified when someone commented on your paper or added to a discussion you had participated in. &lt;a href='http://hunch.net/'&gt;John&lt;/a&gt; and I talked about this after the last ICML and agreed that better notifications should be a priority for future discussion sites like this.&lt;/p&gt;

&lt;p&gt;To address this, I built the &lt;a href='http://mldiscuss.appspot.com/'&gt;new site&lt;/a&gt; from scratch and &amp;#8220;outsourced&amp;#8221; the comment system to &lt;a href='http://disqus.com'&gt;Disqus&lt;/a&gt;. The Disqus service allows anyone to put a comment thread on any webpage by adding a small piece of Javascript. Once this is done, all the comment moderation, user management, notifications, and RSS feeds are all handled through the Disqus interface. While, in a sense, this sort of stuff is &amp;#8220;trivial&amp;#8221; it requires a lot of care to set up the infrastructure correctly and keep it running so I was glad not to have to do that myself.&lt;/p&gt;

&lt;p&gt;The rest of the site &amp;#8211; parsing, managing and serving the ICML paper and author information &amp;#8211; is a few simple python scripts running on top of Google &lt;a href='http://code.google.com/appengine/docs/whatisgoogleappengine.html'&gt;AppEngine&lt;/a&gt;. Along with &lt;a href='http://boscoh.com/'&gt;Bosco&lt;/a&gt;, I&amp;#8217;ve used this combination of AppEngine and Disqus before for a similar service called &lt;a href='http://annotatr.appspot.com/'&gt;annotatr&lt;/a&gt; for commenting on articles in &lt;a href='http://citeulike.org/'&gt;CiteULike&lt;/a&gt;. The development environment for AppEngine is great, allowing you to test everything locally, and deploy with literally the push of a button. I would recommend this approach to anyone wishing to set up a discussion site.&lt;/p&gt;

&lt;p&gt;As an aside, while building ML Dicsuss I realised this quick and dirty style of development epitomises what Noble and Biddle call &lt;em&gt;scrap-heap programming&lt;/em&gt; in Section 13 of their &lt;em&gt;&lt;a href='http://plg.uwaterloo.ca/~migod/846/papers/pomo-oopsla02.pdf'&gt;Notes on Postmodern Programming&lt;/a&gt;&lt;/em&gt;&lt;sup id='fnref:1'&gt;&lt;a href='#fn:1' rel='footnote'&gt;1&lt;/a&gt;&lt;/sup&gt;: exploiting the &amp;#8220;large number of existing programs that the postmodern programmer can scavenge through and reuse&amp;#8221;. Now that more and more programs exist as &lt;a href='prediction-services.html'&gt;services&lt;/a&gt; on the web I think we will see more of this style of development in the future.&lt;/p&gt;

&lt;p&gt;Happy &lt;a href='http://mldiscuss.appspot.com/'&gt;discussing&lt;/a&gt;!&lt;/p&gt;
&lt;div class='footnotes'&gt;&lt;hr /&gt;&lt;ol&gt;&lt;li id='fn:1'&gt;
&lt;p&gt;Just for fun, see if you can guess what part of this paper that I quoted in my wedding speech.&lt;/p&gt;
&lt;a href='#fnref:1' rev='footnote'&gt;&amp;#8617;&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Prediction Services</title>
   <link href="http://mark.reid.name/iem/prediction-services.html"/>
   <updated>2010-05-21T00:00:00+07:00</updated>
   <id>id:/iem/prediction-services</id>
   <content type="html">&lt;p&gt;I have been thinking about learning and prediction as services for some time now. Like all good ideas, they tend to be thought of independently by several people when their time is ripe. Therefore I was not completely surprised when I heard the &lt;a href='http://googlecode.blogspot.com/2010/05/bigquery-and-prediction-api-get-more.html'&gt;news&lt;/a&gt; yesterday that Google has released a new RESTful &lt;a href='http://code.google.com/apis/predict/'&gt;prediction API&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a couple of other bloggers (&lt;a href='http://hunch.net/?p=1383'&gt;John&lt;/a&gt;, &lt;a href='http://behind-the-enemy-lines.blogspot.com/2010/05/google-prediction-api-commoditization.html#comments'&gt;Panos&lt;/a&gt;) have already noted, this is very exciting as it has the potential of making statistical inference a commodity and putting machine learning tools in the hands of everyday developers.&lt;/p&gt;

&lt;h2 id='using_the_api'&gt;Using the API&lt;/h2&gt;

&lt;p&gt;The details are a little scant as the API is not yet open to the public at the moment but, as the &lt;a href='http://code.google.com/apis/predict/docs/faq.html'&gt;FAQ&lt;/a&gt; and &lt;a href='http://code.google.com/apis/predict/docs/samples.html'&gt;sample code&lt;/a&gt; explain, it appears to work as follows:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A data set in CSV format is uploaded to &lt;a href='http://code.google.com/apis/storage/'&gt;Google storage&lt;/a&gt;. This can contain up to 100 million rows of text or numeric features. Each row can be associated with one of up to several hundred classes.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The URL obtained after uploading the data set is POSTed to a second URL, &lt;code&gt;/prediction/v1/train/DATA_ID&lt;/code&gt;, for Google&amp;#8217;s learning algorithm (all URLs are relative to &lt;code&gt;https://googleapis.com&lt;/code&gt;). It is not clear what algorithms are being used behind the scenes for this step but the home page says the API will automatically choose from a variety of techniques.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;The training occurs asynchronously and its progress can be queried by issuing a GET to &lt;code&gt;/prediction/v1/query/DATA_ID&lt;/code&gt;. Once training is completed, this query will return a cross-validated estimate of the learned model&amp;#8217;s accuracy.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;To make a new prediction with the trained model, a POST request containing the data to classify is sent to the &lt;code&gt;/prediction/v1/query/DATA_ID&lt;/code&gt; URL and a label prediction is returned.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Although this is a relatively simple API and, at present, only deals with classification, I believe it has the potential to cover a large proportion of most web developers&amp;#8217; prediction needs (e.g., text classification, sentiment analysis, click-through analysis) as well as several scientific applications.&lt;/p&gt;

&lt;h2 id='related_projects'&gt;Related Projects&lt;/h2&gt;

&lt;p&gt;The Google Prediction API is not the first to offers inferential services over the web but I do think they are the first to focus on building reusable predictors and to do it with a clean API design.&lt;/p&gt;

&lt;p&gt;Some other projects offering prediction services include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href='http://www.uclassify.com/'&gt;uClassify&lt;/a&gt; &amp;#8212; This is probably the closest existing service to Google&amp;#8217;s. It also provides an API for training and predicting but, upon a cursory examination, appears a bit more complicated than the Google prediction API. I believe the &lt;a href='http://www.uclassify.com/Products.aspx'&gt;main algorithm&lt;/a&gt; used by uClassify is a variant of naïve Bayes.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://mlcomp.org'&gt;MLcomp&lt;/a&gt; &amp;#8212; This recently announced service is more aimed at machine learning researchers and provides a convenient way to compare several algorithms on a selection of data sets using a variety of metrics. Unlike Google&amp;#8217;s offering, MLcomp does not make the trained predictors available via an API and focuses more on providing easily repeatable experiments. One nice thing about the MLcomp service is that anyone is free to upload learning algorithms provided they implement a simple &lt;a href='http://mlcomp.org/help/program_info.html'&gt;calling pattern&lt;/a&gt;.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://predict.i2pi.com/'&gt;predict&lt;/a&gt; &amp;#8212; A simpler MLcomp-like service built by &lt;a href='http://i2pi.com/team.html'&gt;Joshua Reich&lt;/a&gt; that lets users upload CSV files to learn from and/or snippets of &lt;a href=''&gt;R&lt;/a&gt; code to run. Once again, the aim is to evaluate algorithms rather than train predictors for subsequent use.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://tunedit.org/'&gt;TunedIT&lt;/a&gt; &amp;#8212; Similar to MLcomp and i2pi&amp;#8217;s &lt;em&gt;predict&lt;/em&gt;, this service aims to make comparing learning algorithms across data sets easier. As far as I can tell, it does not offer an API for running learners and predictors over the web but rather offers users the ability to create data-mining &lt;a href='http://tunedit.org/challenges/docs'&gt;challenges&lt;/a&gt; that other users can compete within.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://expdb.cs.kuleuven.be/expdb/index.php'&gt;ExpDB&lt;/a&gt; &amp;#8212; This is not so much a service as a growing database of experimental results but I thought I&amp;#8217;d include it here as it has a similar focus to the last three projects. The main innovation here is the creation of a language &amp;#8211; &lt;a href='http://expdb.cs.kuleuven.be/expdb/expml.php?tq='&gt;ExpML&lt;/a&gt; &amp;#8211; for describing and querying the parameters, algorithms, data sets and results of machine learning experiments.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;a href='http://glue.rl-community.org/'&gt;RL-Glue&lt;/a&gt; &amp;#8212; While not about prediction &lt;em&gt;per se&lt;/em&gt;, this somewhat older project is related as it offers an API for defining reinforcement learning problems that can be solved in a programming language-independent way.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Of course, there are also many machine learning toolkits such as &lt;a href='http://www.cs.waikato.ac.nz/ml/weka/'&gt;Weka&lt;/a&gt;, &lt;a href='http://www.ailab.si/orange/'&gt;Orange&lt;/a&gt;, &lt;a href='http://elefant.developer.nicta.com.au/'&gt;Elefant&lt;/a&gt;, &lt;a href='http://rattle.togaware.com/'&gt;Rattle&lt;/a&gt; and more that provide implementations of algorithms, but these do not offer them as services.&lt;/p&gt;

&lt;h2 id='future_predictions'&gt;Future Predictions&lt;/h2&gt;

&lt;p&gt;Over the last few years we&amp;#8217;ve seen a &lt;a href='http://www.economist.com/opinion/displayStory.cfm?story_id=15579717&amp;amp;source=hptextfeature'&gt;dramatic increase&lt;/a&gt; in the amount of data being generated and made available over the web (e.g., &lt;a href='http://www.freebase.com/'&gt;Freebase&lt;/a&gt;, &lt;a href='http://dbpedia.org/'&gt;DBpedia&lt;/a&gt;, &lt;a href='http://www.data.gov/'&gt;Data.gov&lt;/a&gt;, &lt;a href='http://www.netflix.com/'&gt;Netflix&lt;/a&gt;, and &lt;a href='http://www.ncbi.nlm.nih.gov/protein'&gt;protein databases&lt;/a&gt;). Also, thanks to services by Google, Amazon and others, there has also been a large-scale commodification of computational power and storage.&lt;/p&gt;

&lt;p&gt;There are a handful of companies at present &amp;#8212; &lt;a href='http://flightcaster.com/'&gt;Flightcaster&lt;/a&gt;, for example &amp;#8212; who have realised that there is immense opportunity at the intersection of these developments to start applying large-scale machine learning. Hopefully, what the Google Prediction API and other services will provide is the spark for an explosion of new and creative approaches to distilling knowledge from raw information.&lt;/p&gt;

&lt;p&gt;I will be watching how this all unfolds with great interest.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Attending AISTATS</title>
   <link href="http://mark.reid.name/iem/attending-aistats.html"/>
   <updated>2010-05-09T00:00:00+07:00</updated>
   <id>id:/iem/attending-aistats</id>
   <content type="html">&lt;p&gt;Provided there is no further volcanic disruptions coming from Iceland, I will be in Sardinia, Italy on Wednesday for &lt;a href='http://www.aistats.org/'&gt;AISTATS 2010&lt;/a&gt;. As well as being able to indulge in what I imagine to be great food and coffee, I&amp;#8217;m also looking forward to engaging with a very interesting looking &lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/'&gt;program&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some of the posters and talks I&amp;#8217;m looking forward to include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/kakade10a.html'&gt;Learning Exponential Families in High-Dimensions: Strong Convexity and Sparsity&lt;/a&gt;&lt;/em&gt; by Kakade, Shamir, Sindharan and Tewari&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/ma10a.html'&gt;Exploiting Feature Covariance in High-Dimensional Online Learning&lt;/a&gt;&lt;/em&gt; by Ma, Kulesza, Dredze, Crammer, Saul, and Pereira&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/shivaswamy10a.html'&gt;Empirical Bernstein Boosting&lt;/a&gt;&lt;/em&gt; by Shivaswamy and Jebara&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/usunier10a.html'&gt;Guarantees for Approximate Incremental SVMs&lt;/a&gt;&lt;/em&gt; by Usunier, Bordes, and Bottou&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;&lt;em&gt;&lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/weiss10a.html'&gt;Structured Prediction Cascades&lt;/a&gt;&lt;/em&gt; by Weiss and Taskar&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;#8217;ll be standing by a poster on Friday explaining &lt;a href='http://axiom.anu.edu.au/~williams/'&gt;Bob Williamson&lt;/a&gt; and my &lt;a href='http://jmlr.csail.mit.edu/proceedings/papers/v9/reid10a.html'&gt;work&lt;/a&gt; on some characterisations of the convexity of a natural class of losses for binary class &lt;a href='http://mark.reid.name/iem/proper-losses.html'&gt;probability estimation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Please drop by and say hello if you are also going to be at AISTATS.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Upcoming ALT and DS Conferences</title>
   <link href="http://mark.reid.name/iem/upcoming-alt-ds.html"/>
   <updated>2010-04-13T00:00:00+07:00</updated>
   <id>id:/iem/upcoming-alt-ds</id>
   <content type="html">&lt;p&gt;Two traditionally co-located international conferences—&lt;a href='http://conflate.net/alt10'&gt;Algorithmic Learning Theory&lt;/a&gt; and &lt;a href='http://conflate.net/ds10'&gt;Discovery Science&lt;/a&gt;—will be hosted in Canberra, Australia in October this year. One of the reasons (amongst many) that this blog has languished recently is that I am one of the local organisers. &lt;a href='http://cs.anu.edu.au/~Eric.McCreath/'&gt;Eric McCreath&lt;/a&gt; is the other.&lt;/p&gt;

&lt;p&gt;One of my jobs as local organiser is to make sure every potential attendee knows about these conferences. I thought that a bit of shameless promotion would be as good a way as any to bring &lt;em&gt;Inductio Ex Machina&lt;/em&gt; back from the dead. So here goes&amp;#8230;&lt;/p&gt;

&lt;h2 id='important_dates'&gt;Important Dates&lt;/h2&gt;

&lt;p&gt;Before I even tell you what the conferences are about I need you to do the following.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Take out your calendars and with your most indelible pen inscribe the these dates:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;May 12, 2010&lt;/strong&gt; &amp;#8212; ALT (full paper) and DS (abstract) deadline &lt;br /&gt;&lt;strong&gt;June 17, 2010&lt;/strong&gt; &amp;#8212; Notifications of acceptance sent out &lt;br /&gt;&lt;strong&gt;October 6–8, 2010&lt;/strong&gt; &amp;#8212; Conferences are run&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Prepare some amazingly ground-breaking paper for submission.&lt;/p&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;p&gt;Book your flights to Canberra, Australia for October &lt;em&gt;right now&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id='the_conferences'&gt;The Conferences&lt;/h2&gt;

&lt;p&gt;Together, the ALT and DS conferences cover a broad range of research areas within machine learning.&lt;/p&gt;

&lt;p&gt;The ALT conference has been running for 20 years and, as its name suggests, its focus is on foundational issues in the theory of machine learning. A full list of topics can be found in the &lt;a href='http://www-alg.ist.hokudai.ac.jp/~thomas/ALT10/alt10c.html'&gt;ALT Call for Papers&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The DS conference has been running for 12 years and emphasises the development, analysis and application of algorithmic methods of knowledge discovery in scientific domains. The &lt;a href='http://www.cse.unsw.edu.au/~achim/DS10/cfp.html'&gt;DS Call for Papers&lt;/a&gt; has more information.&lt;/p&gt;

&lt;h2 id='invited_speakers'&gt;Invited Speakers&lt;/h2&gt;

&lt;p&gt;We are very lucky to have enticed some great speakers, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href='http://www.cs.rhul.ac.uk/home/alexc/'&gt;Alexander Clark&lt;/a&gt; from Royal Holloway, University of London&lt;/li&gt;

&lt;li&gt;&lt;a href='http://users.soe.ucsc.edu/%7Emanfred/'&gt;Manfred Warmuth&lt;/a&gt; from UC Santa Cruz&lt;/li&gt;

&lt;li&gt;&lt;a href='http://stat-www.berkeley.edu/%7Ebartlett/'&gt;Peter Bartlett&lt;/a&gt; from UC Berkeley&lt;/li&gt;

&lt;li&gt;&lt;a href='http://www.ailab.si/ivan/'&gt;Ivan Bratko&lt;/a&gt; from the University of Ljubljana, and&lt;/li&gt;

&lt;li&gt;&lt;a href='http://ww2.cs.mu.oz.au/%7Erao/'&gt;Ramamohanarao (Rao) Kotagiri&lt;/a&gt; from the University of Melbourne.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Personally, I&amp;#8217;m very excited to hear Manfred and Peter talk as they are both fantastic learning theorists and I&amp;#8217;ve been reading a lot of their work recently.&lt;/p&gt;

&lt;h2 id='bonus_summer_school'&gt;Bonus Summer School!&lt;/h2&gt;

&lt;p&gt;As an added bonus, both of these conferences will be held just after a co-located &lt;a href='http://canberra10.mlss.cc/'&gt;Machine Learning Summer School&lt;/a&gt; running from the 27th of September until the 6th of October.&lt;/p&gt;

&lt;p&gt;All in all, it is shaping up to be a great combination so if you&amp;#8217;ve ever thought you&amp;#8217;d like to visit Australia and wanted a good, machine-learning excuse, here it is.&lt;/p&gt;

&lt;p&gt;Hope to see you here!&lt;/p&gt;</content>
 </entry>
 
 
</feed>